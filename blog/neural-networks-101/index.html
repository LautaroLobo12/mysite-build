<!doctype html> <html lang=en> <head> <meta charset=utf-8> <meta name=viewport content="width=device-width, initial-scale=1"> <title>Neural Networks 101 | Lautaro Jordan Lobo Ravarotto</title> <link rel=alternate href="/feed.xml" type="application/atom+xml" title="Atom Feed"> <link rel=stylesheet href="/stylesheets/all-3ff0324d.css"> </head> <body> <nav class=main-nav> <a href="/"><span class=arrow>←</span> Home</a> </nav> <section id=wrapper> <article class=post> <header> <img src="/images/ANN-cover-d32a0480.webp"></img> <h1>Neural Networks 101</h1> <h2 class=date>31 July 2019</h2> </header> <section id=post-body> <script type="application/ld+json">
{
 "@context": "https://schema.org", 
 "@type": "BlogPosting",
 "url": "https://lautarolobo.xyz/blog/neural-networks-101",
 "mainEntityOfPage": "https://lautarolobo.xyz/blog/neural-networks-101",
 "headline": "Neural Networks 101",
 "alternativeHeadline": "A friendly introduction to Artificial Neural Networks",
 "genre": "Neural Networks", 
 "keywords": [
  "Artificial Neural Networks", 
  "Neural Networks", 
  "Computer Science", 
  "Artificial Intelligence",
  "AI",
  "Machine Learning",
  "Deep Learning"
],  
 "wordcount": "689",
 "datePublished": "2019-07-31",
 "dateCreated": "2019-07-31",
 "dateModified": "2019-07-31",
 "description": "How Artifical Neural Networks work? Well, here it is! Finally!",
 "isFamilyFriendly": "true",
 "image": "https://lautarolobo.xyz/images/ANN-cover-d2927098.jpg",
 "publisher": {
  "@type": "Organization",
  "name": "Lautaro Jordan Lobo Ravarotto",
  "url": "https://lautarolobo.xyz",
  "logo": {  
   "@type": "ImageObject",
   "author": "Lautaro Jordan Lobo Ravarotto",
   "url": "https://imgsafe.org/image/5709e8ceba.png"
   }
  },
 "author": {
  "@type": "Person",
  "name": "Lautaro Jordan Lobo Ravarotto",
  "url": "https://lautarolobo.xyz",
  "email": "contact@lautarolobo.xyz",
  "birthDate": "2000-04-12",
  "gender": "male",
  "nationality": "Argentina",
  "alumniOf": {
   "@type": "CollegeOrUniversity",
   "legalName": "National University of Córdoba",
   "sameAs": "https://en.wikipedia.org/wiki/National_University_of_C%C3%B3rdoba",
   "location": {
    "@type": "Place",
    "sameAs": "http://unc.edu.ar",
    "name": "National University of Córdoba",
    "address": {
      "@type": "PostalAddress",
      "streetAddress": "Av. Haya de la Torre s/n",
      "addressCountry": "Argentina",
      "addressLocality": "Córdoba",
      "postalCode": "5000" 
      }
     }
    }
   },
 "creator": {
  "@type": "Person",
  "name": "Lautaro Jordan Lobo Ravarotto",
  "url": "https://lautarolobo.xyz",
  "email": "contact@lautarolobo.xyz",
  "birthDate": "2000-04-12",
  "gender": "male",
  "nationality": "Argentina",
  "alumniOf": {
   "@type": "CollegeOrUniversity",
   "legalName": "National University of Córdoba",
   "sameAs": "https://en.wikipedia.org/wiki/National_University_of_C%C3%B3rdoba",
   "location": {
    "@type": "Place",
    "sameAs": "http://unc.edu.ar",
    "name": "National University of Córdoba",
    "address": {
      "@type": "PostalAddress",
      "streetAddress": "Av. Haya de la Torre s/n",
      "addressCountry": "Argentina",
      "addressLocality": "Córdoba",
      "postalCode": "5000" 
      }
     }
    }   
   }
  }
 }
},
</script> <blockquote> <p>This post is about Artificial Neural Networks. Computer Science != Biology.</p> </blockquote> <h2>Summary</h2> <ul> <li>What is a Neural Network?</li> <li>What are Neural Networks used for?</li> <li>Structure of a Neural Network</li> <li>How Neural Networks work</li> <li>How to improve the learning process</li> </ul> <h2>What is a Neural Network?</h2> <p>A Neural Network is a computational model inspired by biological neural networks, like yours and mine.</p> <p><img src="/images/ANN-comparison-a841f410.png" alt="Ann comparison"/></p> <p>A key concept here is that these models learn from examples (inputs), without being programmed with any task-specific rule.</p> <h2>What are they used for?</h2> <ul> <li>Image and voice recognition.</li> <li>Text generation.</li> <li>Genetical analysis.</li> <li>Language translations.</li> <li>Autonomous driving.</li> <li>Fraud prevention.</li> </ul> <h2>Structure of a Neural Network</h2> <h3>Different layers</h3> <ul> <li>Input</li> <li>Hidden (interconnected)</li> <li>Output</li> </ul> <p><img src="/images/Neural-Network-Structure-9402face.jpg" alt="Structure of a Neural Network"></p> <p>Each layer has a specific amount of neurons. And every neuron connects with another neuron from a different layer, it can&rsquo;t connect to a neuron from the same layer unless you use a <a href="https://towardsdatascience.com/recurrent-neural-networks-d4642c9bc7ce" target=_blank>Recurrent Neural Network.</a></p> <h2>How Neural Networks work</h2> <p>Explaining this is not a simple task.</p> <p>First of all, your Neural Network must &ldquo;learn&rdquo;. In other words, you must train them.</p> <p>How do you train a Neural Network? </p> <p>Well, you pass information to the input layer, that is already processed. This is easier to get through an example. </p> <p>Let&rsquo;s say you pass to the input layer 500 cat pictures, with the tag &lsquo;cat pictures&rsquo;, so the Neural Network knows that those are cat pictures. Then, you start to pass some cat pictures not tagged, and the network will taggit on its own. Also, you can pass it some car pictures, bird pictures, a non-sense picture, whatever, and your network should not taggit with &lsquo;cat picture&rsquo;.</p> <p>if it tags some images wrong, you can warn the network of its mistakes, and it will learn from them.</p> <p>You can repeat this process many times until you are happy with how your Neural Network works, and there you have it. A trained Neural Network, ready to work.</p> <p>Now use it! Pass to the input layer some non-tagged pictures, and see how well it does it.</p> <p>If the output is not what you expected, you should train it more, or improve the learning process. I&rsquo;ll talk more about this in the next lines.</p> <p>But now, let&rsquo;s get nerdy.</p> <p>Your Neural Network works because identifies a pattern on the &lsquo;cat pictures&rsquo; images. Then starts to &ldquo;memorize&rdquo; that pattern&hellip; somehow learns that this particular set of pixels (a bunch of ones &amp; zeros) goes inside the &lsquo;cat pictures&rsquo; tag, then it can tag cat images without our help.</p> <p>Every neuron gets these inputs, sums all those weights, and outputs come out. Before going to the next layer, this output goes through an activation function. This function adds to the output an “activation rate”, telling the next neuron much important is this data. More in-depth math in <a href="https://medium.com/coinmonks/the-mathematics-of-neural-network-60a112dd3e05" target=_blank alt="The Mathematics of Neural Networks on Medium">here.</a></p> <table> <tr> <th><img src="/images/Neuron-Structure-237bc0d8.png" alt="Structure of a Neuron"></td> </tr> <tr> <td> Inputs coming in, sum, activation function, outputs coming out. </td> </tr> </table> <p>This is how neurons process data but wait, there&rsquo;s more!</p> <p>These outputs can go to the next layer, and also can go to a previous layer. </p> <p>This process when the data goes to a previous layer is known as backpropagation. Thanks to it, data gets processed several times. This may help you or not, depending on the problem that you are willing to solve with your network.</p> <p>Also, a friendly advice, <em>size matter</em>. If your network&rsquo;s size is too small or too big, it won&rsquo;t be able to group the data, the outputs will always be wrong, so you would need to find your network&rsquo;s perfect size. </p> <p>In the majority of cases, you would find this through trial and error, until you build your intuition.</p> <h2>How to improve the learning process</h2> <p>Through regularization. </p> <p>This is a broad concept, that includes a bunch of techniques. More common ones are weight regularization, <a href="https://en.wikipedia.org/wiki/Early_stopping">early stopping</a>, learning rate decay, <a src="https://www.quora.com/What-is-data-augmentation-in-deep-learning" target=_blank>data augmentation,</a> and dropout. </p> <p>These are all measurements to prevent <a href="https://youtu.be/DEMmkFC6IGM" target=_blank alt="Neural Networks - Overfitting">overfitting</a> and <a href="https://youtu.be/0h8lAm5Ki5g" target=_blank alt="Artificial Neural Networks: Underfitting">underfitting.</a></p> <p><hr></p> <p>Want to become an expert on Neural Networks? Get the exclusive lectures <a href="javascript:;" onclick="ml_webform_1427060('show')">right into your inbox!</a></p> <p>Do you have any questions? Do you think that I may be missing something? Write it down in the comments! </p> <p>See ya!</p> <script>
    var ml_webform_1427060 = ml_account('webforms', '1427060', 'n8u0c3', 'load');
    ml_webform_1427060('animation', 'fadeIn');
</script> </section> </article> <footer id=post-meta> <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script> <a href="/"> <img class=avatar src="/images/100px-3211424c.jpg" alt=Avatar> <div class=details> <div class=dark>Lautaro Jordan Lobo Ravarotto</div> <div class=light>Web Developer | Computer Science Student</div> </div> </a> <div class=sharing> <a href="https://twitter.com/share?text=Neural Networks 101&url=https://lautarolobo.xyz/blog/neural-networks-101/" target=_blank> <span class=icon-twitter></span> </a> <a href="https://www.facebook.com/sharer/sharer.php?u=https://lautarolobo.xyz/blog/neural-networks-101/" target=_blank> <span class=icon-facebook></span> </a> <a href="http://www.linkedin.com/shareArticle?mini=true&url=https://lautarolobo.xyz/blog/neural-networks-101/&title=Neural Networks 101&source=https://lautarolobo.xyz" target=_blank> <span class=icon-linkedin></span> </a> </div> <div class=newsletter-wrapper> <div class=ml-form-embed data-account="1607694:c8w6g9c9z6" data-form="1426892:g8s3m6"> </div> </div> </footer> <div id=disqus_thread></div> <script>
  var disqus_shortname = 'lautarolobo';
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script> <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel=nofollow>comments powered by Disqus.</a></noscript> <footer id=footer> <script>
      (function(m,a,i,l,e,r){ m['MailerLiteObject']=e;function f(){
      var c={ a:arguments,q:[]};var r=this.push(c);return "number"!=typeof r?r:f.bind(c.q);}
      f.q=f.q||[];m[e]=m[e]||f.bind(f.q);m[e].q=m[e].q||f.q;r=a.createElement(i);
      var _=a.getElementsByTagName(i)[0];r.async=1;r.src=l+'?v'+(~~(new Date().getTime()/1000000));
      _.parentNode.insertBefore(r,_);})(window, document, 'script', 'https://static.mailerlite.com/js/universal.js', 'ml');
    
      var ml_account = ml('accounts', '1607694', 'c8w6g9c9z6', 'load');
      </script> <p class=small>© Lautaro Jordan Lobo Ravarotto 2020</p> </footer> </section> <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-138446504-1', 'auto');
  ga('send', 'pageview');
</script> </body> </html>